{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6JrSxirJu3-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/student.csv\")"
      ],
      "metadata": {
        "id": "qY7oHu_mvoBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-Do 1: Load and Explore Dataset"
      ],
      "metadata": {
        "id": "tFVWvIYnv6za"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hv1bki9utV5",
        "outputId": "c921372a-d69a-4e02-d324-daa84c8080ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 rows:\n",
            "   Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "\n",
            "Bottom 5 rows:\n",
            "     Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n"
          ]
        }
      ],
      "source": [
        "#Print top 5 and bottom 5 rows\n",
        "print(\"Top 5 rows:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nBottom 5 rows:\")\n",
        "print(data.tail())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset information\n",
        "print(\"\\nDataset Info:\")\n",
        "data.info()\n",
        "\n",
        "#Descriptive statistics\n",
        "print(\"\\nDataset Description:\")\n",
        "print(data.describe())\n",
        "\n",
        "#Split Features (X) and Label (Y)\n",
        "X = data[['Math', 'Reading']].values   # Features\n",
        "Y = data['Writing'].values             # Target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-frrp-GwE8-",
        "outputId": "a3d1bc11-d779-49c8-9a94-98772f6b1996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "\n",
            "Dataset Description:\n",
            "              Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-Do 2: Create Matrices\n",
        "\n"
      ],
      "metadata": {
        "id": "9ftBnN-GwOPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of Y:\", Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP9qQcb5wPpD",
        "outputId": "eeec7610-d42b-4a04-eba6-9e772f5ce738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1000, 2)\n",
            "Shape of Y: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-Do 3: Train-Test Split (from scratch)\n",
        "\n"
      ],
      "metadata": {
        "id": "7DjZkBBiwVJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "Lj_iZPuMwUyW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-Do 4: Implement Cost Function"
      ],
      "metadata": {
        "id": "aLxLMJGVwbSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(X, Y, W):\n",
        "    \"\"\"\n",
        "    Computes Mean Squared Error Cost\n",
        "    \"\"\"\n",
        "    n = len(Y)\n",
        "    Y_pred = np.dot(X, W)\n",
        "    cost = (1 / (2 * n)) * np.sum((Y_pred - Y) ** 2)\n",
        "    return cost"
      ],
      "metadata": {
        "id": "A7a_7cxIwUu6"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-Do 5: Test the Cost Function\n",
        "\n"
      ],
      "metadata": {
        "id": "fMrnUvmtwgE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To-Do-5: Test Cost Function\n",
        "X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "Y_test = np.array([3, 7, 11])\n",
        "W_test = np.array([1, 1])\n",
        "\n",
        "cost = cost_function(X_test, Y_test, W_test)\n",
        "\n",
        "if cost == 0:\n",
        "    print(\"Proceed Further\")\n",
        "else:\n",
        "    print(\"Something went wrong\")\n",
        "\n",
        "print(\"Cost:\", cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pA6pEpCwhCH",
        "outputId": "07785cb3-e8d6-4b30-8934-aa40a2a4090a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed Further\n",
            "Cost: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-Do 6: Implement Gradient Descent"
      ],
      "metadata": {
        "id": "e_biTU8NwlAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    cost_history = []\n",
        "    m = len(Y)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        #  Prediction\n",
        "        Y_pred = np.dot(X, W)\n",
        "\n",
        "        #  Error\n",
        "        loss = Y_pred - Y\n",
        "\n",
        "        #  Gradient\n",
        "        dw = (1 / m) * np.dot(X.T, loss)\n",
        "\n",
        "        #  Update Weights\n",
        "        W = W - alpha * dw\n",
        "\n",
        "        #  Cost\n",
        "        cost = cost_function(X, Y, W)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return W, cost_history\n"
      ],
      "metadata": {
        "id": "DQi45ze2wl8c"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-Do 7: Test Gradient Descent"
      ],
      "metadata": {
        "id": "lXJbYB1iwrRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "X = np.random.rand(100, 3)\n",
        "Y = np.random.rand(100)\n",
        "W = np.random.rand(3)\n",
        "\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "final_params, cost_history = gradient_descent(X, Y, W, alpha, iterations)\n",
        "\n",
        "print(\"Final Parameters:\", final_params)\n",
        "print(\"First 10 Cost values:\", cost_history[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WgFFhh1wr7W",
        "outputId": "a885ea8b-a69b-4e8b-8ecc-ea316e0ef62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Parameters: [0.2055 0.543  0.1039]\n",
            "First 10 Cost values: [np.float64(0.10711197094660153), np.float64(0.10634880599939901), np.float64(0.10559826315680618), np.float64(0.10486012948320558), np.float64(0.1041341956428534), np.float64(0.10342025583900626), np.float64(0.1027181077540776), np.float64(0.1020275524908062), np.float64(0.10134839451441931), np.float64(0.1006804415957737)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-Do 8: Implement RMSE (Root Mean Squared Error)\n",
        "\n"
      ],
      "metadata": {
        "id": "n_zwHaOuwwIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "    return np.sqrt(np.mean((Y - Y_pred) ** 2))\n"
      ],
      "metadata": {
        "id": "ZZ2ziUGdwxIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-Do 9: Implement R² (Coefficient of Determination)\n"
      ],
      "metadata": {
        "id": "-xd3_Fqyw1-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def r2(Y, Y_pred):\n",
        "    mean_y = np.mean(Y)\n",
        "    ss_tot = np.sum((Y - mean_y) ** 2)\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    return 1 - (ss_res / ss_tot)\n"
      ],
      "metadata": {
        "id": "hl40NdZuw3Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### To-Do 10: Create Main Integration Function\n"
      ],
      "metadata": {
        "id": "QCkeTAsNw6sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To-Do-10: Integrate Everything\n",
        "def main():\n",
        "    # Load Data\n",
        "    data = pd.read_csv(\"/content/drive/MyDrive/student.csv\")\n",
        "\n",
        "    X = data[['Math', 'Reading']].values\n",
        "    Y = data['Writing'].values\n",
        "\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Initialize\n",
        "    W = np.zeros(X_train.shape[1])\n",
        "    alpha = 0.00001\n",
        "    iterations = 1000\n",
        "\n",
        "    # Train Model\n",
        "    W_optimal, cost_history = gradient_descent(\n",
        "        X_train, Y_train, W, alpha, iterations\n",
        "    )\n",
        "\n",
        "    # Predictions\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "    # Evaluation\n",
        "    print(\"Final Weights:\", W_optimal)\n",
        "    print(\"First 10 Cost Values:\", cost_history[:10])\n",
        "    print(\"RMSE:\", rmse(Y_test, Y_pred))\n",
        "    print(\"R2 Score:\", r2(Y_test, Y_pred))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPv1o3bkw9_K",
        "outputId": "124424ac-e511-452a-e0d4-60b16586fafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.3481 0.6461]\n",
            "First 10 Cost Values: [np.float64(2013.165570783755), np.float64(1640.286832599692), np.float64(1337.0619994901588), np.float64(1090.4794892850578), np.float64(889.9583270083234), np.float64(726.8940993009545), np.float64(594.2897260808594), np.float64(486.4552052951635), np.float64(398.7634463599484), np.float64(327.4517147324688)]\n",
            "RMSE: 5.2798239764188635\n",
            "R2 Score: 0.8886354462786421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To-Do 11:"
      ],
      "metadata": {
        "id": "OfcwlrDhL-Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Model Performance\n",
        "\n",
        "The performance of the model is acceptable.\n",
        "\n",
        "The model does not overfit because it is a simple linear regression model with only two features and no bias term.\n",
        "The model does not underfit because it achieves a reasonably low RMSE and a good R² value, indicating that it explains a significant portion of the variance in the writing marks."
      ],
      "metadata": {
        "id": "wSryhZEiLu19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Effect of Learning Rate\n",
        "\n",
        "Different learning rates were tested and the following observations were made:\n",
        "\n",
        "With a very small learning rate, the cost decreases very slowly and the model takes longer to converge.\n",
        "\n",
        "With a very large learning rate, the cost oscillates or diverges and the model becomes unstable.\n",
        "\n",
        "With a moderate learning rate, the cost decreases smoothly and the model converges efficiently.\n",
        "\n",
        "Therefore, a moderate learning rate gives the best performance."
      ],
      "metadata": {
        "id": "dMIVwNYwL0SG"
      }
    }
  ]
}